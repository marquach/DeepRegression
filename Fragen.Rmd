---
title: "Fragen"
output: html_document
date: "2023-01-09"
---

## Fragen:

- Bei precalc_gam muss nicht verändert

- Alles bis zu return_prepoc = T kann verwendet bzw. muss nicht verändert werden
  - scheinbar nicht so ganz vll doch nicht
  - Output sind dann die parsed_formulas_contents (Output ist in test_data abgespeichert)
  - \$layer problematisch! (wegen layer_args, layer_class, usw.)
    - Sollte aber eigentlich passen wenn layer_generator torch nutzt
    - (Überlegung: Sollte bei layer_class dann bei spline z.b. layer_spline_torch (siehe ..._functions dafür) stehen)


- Woher kommt layer_class, layer_args (subnetwork_init) bei \$layer() ??? (Wichtig!)
  - return(do.call(layer_class, layer_args)(x)) hat nur "x" als input
  - nochmal genauer anschauen (Stichwort: "enviroments")
  - sollte aus parent.env(environment()) kommen (nicer trick)
    - parent.env(environment())\$layer_args,
    - parent.env(environment())\$layer_class
    
- Fragen zu deepregression:::process_terms:
  - create_P muss nicht verändert werden
  - procs beinhaltet prozessoren für alle specials(=splines, lasso, ...)
  - control und alle processors werden args hinzugefügt
  - Prozessor vom jeweiligen special wird mit args genutzt genutzt
  - Jedes submodul hat eigenen Datensatz (data_trafo())
    - also Intercept lauter 1er, s(xa) hat xa, deep_model(x1, x2, x3) hat x1, x2, x3 usw.
    - gleiches dann nochmal für anderen Verteilungsparameter
    - Modul bekommt also seinen eigenen Input
      - model_builder dann vll sowie bei NN_VerständnisSkript.R ganz am Ende
      - hat noch nicht mit luz funktioniert
    - Hier input_dim für spätere Initialisierung ergänzgen (bei args)
      
- manche processor nutzen layer_generator (gam_processor) und andere nicht (multiply_processor)
  - hier als Input engine=torch um die Layer mit Torch zu initialisieren?
  - Sollte man anpassen, dass alle layer_generator() nutzen und dann layer_generator(..., engine = Torch)
  - layer_class nutzt dann bei gam_processor layer_spline_torch oder halt engine = Torch und dann nur die torch layer ziehen
  
- makeInputs erstellt Keras Tensoren mit Shape(None,...)
  - Bei Torch muss Shape immer gleich angegeben werden, oder?
  - Hier leeren (torch_empty(Dimensionen)) oder direkt mit Daten (torch_tensor(...))
  
- Fragen subnetwork_init:
  - outputs in subnetwork_init wird auf shape(None, 1) bei allen reduziert. Warum?
    - Da Ergebnis des NN pro Beobachtung ein skalar ist
  - summary_layer per default layer_add_identity
    - Torch hat m.M.n. kein layers.add
  - subnetwork_init noch nicht ganz klar
    - subnetwork_init baut tensoren (bis auf gampart) und layer
    - enthält tensoren für inputs und outputs
    - bei sturkturieten Parts nur dense layer bzw. nn_linear
    - summary_layer setzt diese dann zusammen (z.b. layer_add_identity)
    - return ist liste aus input[keep_inputs_in_return] und output


- Netzwerk bei uns über nn_module() bzw. nn_sequential() in deepregression()

- model_builder bei uns?
  - deepreg. nutzt keras_dr (bzw. keras_model)
  - luz mit setup()?
  
  
- Einfachste Fälle überlegen für Torch 
  - (orthogonalize = F) immer nutzen
  - Intercept Only
  - nur lineares Model
  - spline
  - nur deep_model


- Nächste Schritte?
  - makeInputs() anpassen
    - brauchen hier dann alle Dimensionen, da shape(None, ...) bei Torch nicht geht
    - bei den procs die input_dim zu vektor machen, da kann mit (torch_empty(Dimensionen)) gearbeitet werden
  - layer_generator direkt ändern?
  - oder erstmal ..._processor von einfachsten Fällen anpassen und mit deepregression testen
    - int_processor
    - lin_processor
    - gam_processor
    
  
